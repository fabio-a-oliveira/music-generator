{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "searching-mainstream",
   "metadata": {},
   "source": [
    "## Creating original computer-generated music inspired by Bach's chorales\n",
    "\n",
    "In this notebook, we create a model that will be able to generate original music after being trained on a large corpus comprised of J.S. Bach's chorale pieces.   \n",
    "\n",
    "Some high-level features of this work: \n",
    "* This project is inspired by an exercise proposed in chapter 15 of the _Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow_ book. You can check out the author's implementation in [this notebook](https://github.com/ageron/handson-ml2/blob/master/15_processing_sequences_using_rnns_and_cnns.ipynb)      \n",
    "* The model is based on an architecture consisting of stacked Gated Recurrent Units followed by a dense layer, regularized with droupout, and stabilized with layer normalization,          \n",
    "* Training is performed in a many-to-many scheme: at each step, the model tries to predict the next note (as opposed to a many-to-one scheme, where the model would be exposed to a sequence of notes and try to predict the last one)   \n",
    "* The dataset is available at [this link](https://raw.githubusercontent.com/ageron/handson-ml2/master/datasets/jsb_chorales/jsb_chorales.tgz) and contains _.csv_ files for each of the pieces    \n",
    "* The dataset is split into train (229 pieces), validation (76 pieces) and test (77 pieces) partitions (yes, Bach was a tremendous workaholic!)   \n",
    "* Each sample in the _.csv_ files contains 4 integer values ranging from 36 to 81 corresponding to 4 notes (one for each of the four voices) that are sung simultaneously, with an uniform note duration of half a beat      \n",
    "* In order to train the model, each note is converted to a one-hot encoding to represent each of the possible notes, plus 0 for silence and -1 to indicate the end of a piece\n",
    "* The dataset is augmented so that, before each training epoch, each of the pieces is randomly transposed by a number of steps in the range of -5 to 6 - this ensures that the model is equally exposed to musical patterns in all different keys   \n",
    "* After training, the model is used to generate new music one note at a time by choosing each note randomly according to the probabilities generated by the softmax layer of the neural network      \n",
    "* The original music is saved to midi files using the _mido_ package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virgin-country",
   "metadata": {},
   "source": [
    "### Importing packages\n",
    "\n",
    "Besides the usual suspects, we also import the _mido_ package for creating and saving the _.mid_ files, as well as some functions from _os_ and _os.path_ to manipulate files and directories.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adolescent-receipt",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "from os import getcwd, listdir, mkdir\n",
    "from os.path import join\n",
    "import mido\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operating-thirty",
   "metadata": {},
   "source": [
    "### Dataset preparation   \n",
    "\n",
    "The dataset is downloaded from [this link](https://raw.githubusercontent.com/ageron/handson-ml2/master/datasets/jsb_chorales/jsb_chorales.tgz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acknowledged-tomato",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### download/unzip dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-resident",
   "metadata": {},
   "source": [
    "Some helper functions are required to encode the music using one-hot encoding and decode the results from the softmax layer. Another helper function is defined to transpose an entire piece by a selected number of half steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dedicated-possibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 81+6 and 36-5 due to transposing randomly between -5 half-steps and +6 half-steps\n",
    "\n",
    "def one_hot_encoding(note):\n",
    "    vector = np.zeros(((81+6)-(36-5)+3))\n",
    "    if note == -1: # eof\n",
    "        vector[0] = 1\n",
    "    elif note == 0: # silence\n",
    "        vector[1] = 1\n",
    "    elif note >= (36-5) and note <= (81+6):\n",
    "        vector[note-(36-5)+2] = 1\n",
    "    else:\n",
    "        raise Exception('invalid note, should be either -1 (eof), 0 (silence), or [36-5,81+6]; received {}'.format(note))\n",
    "    return vector\n",
    "\n",
    "def one_hot_decoding(vector):\n",
    "    if vector.flatten()[0] == 1: # eof\n",
    "        note = -1\n",
    "    elif vector.flatten()[1] == 1: # silence\n",
    "        note = 0\n",
    "    else:\n",
    "        note = vector.flatten().argmax() + (36-5) - 2\n",
    "    return note\n",
    "\n",
    "def transpose_note(note, interval):\n",
    "    if note >= (36-5) and note <= (81+6):\n",
    "        transposed = note + interval\n",
    "    else:\n",
    "        transposed = note\n",
    "    return transposed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spare-sphere",
   "metadata": {},
   "source": [
    "Next, some functions are defined to systematically prepared the train, valid and test datasets using tensorflow's data API.   \n",
    "\n",
    "The make_dataset() function calls load_partition() to create a dataset consisting of a list of the files in each partition. This function then zips together each file and a randomly selected number of steps by which the piece will be transposed.   \n",
    "\n",
    "Since the number of steps is randomly generated via a generator function, this quantity will be different for each piece and will be resampled at each epoch. This ensures that the model will be trained with each of the pieces transposed to several different keys, ensuring variability and improving generalization.   \n",
    "\n",
    "After that, the parse_csv() function is called on each of the dataset entries (at this point, a file and a number of steps to transpose it by) via the flat_map() method. The parse_csv() function reads the _.csv_ file associated with one piece, decodes it, transposes all the notes and adds four end-of-file identifiers (-1).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "identical-coupon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_random_transpose():\n",
    "    yield tf.random.Generator.from_non_deterministic_state().uniform(shape=[], minval=-5, maxval=6+1, dtype=tf.dtypes.int32).numpy()    \n",
    "\n",
    "def parse_csv(file, interval): # added interval argument\n",
    "    dataset_parsed = tf.data.TextLineDataset(file).skip(1)\n",
    "    defaults = [0]*4\n",
    "    dataset_parsed = dataset_parsed.map(lambda line: tf.stack(tf.io.decode_csv(line, defaults)))\n",
    "    \n",
    "    dataset_parsed = dataset_parsed.unbatch()    \n",
    "    dataset_interval = tf.data.Dataset.from_tensor_slices([interval]).repeat()\n",
    "    dataset_parsed = tf.data.Dataset.zip((dataset_parsed, dataset_interval))\n",
    "    dataset_transposed = dataset_parsed.map(transpose_note)\n",
    "    \n",
    "    eof = tf.data.Dataset.from_tensor_slices([-1,-1,-1,-1])\n",
    "    dataset_transposed = dataset_transposed.concatenate(eof)\n",
    "    \n",
    "    return dataset_transposed\n",
    "\n",
    "def load_partition(partition='train'):\n",
    "    filename = listdir(join(getcwd(), 'bach-chorales', partition))\n",
    "    files = []\n",
    "    for file in filename:\n",
    "        files.append(join(getcwd(), 'bach-chorales', partition, file))\n",
    "    dataset = tf.data.Dataset.list_files(files)\n",
    "    \n",
    "    dataset_random_transpose = tf.data.Dataset.from_generator(generator_random_transpose, output_types=tf.dtypes.int32)\n",
    "    num_pieces = dataset.cardinality().numpy()\n",
    "    dataset = tf.data.Dataset.zip((dataset, dataset_random_transpose.repeat(num_pieces)))\n",
    "    \n",
    "    dataset = dataset.flat_map(parse_csv) # flat_map ~ simple interleave\n",
    "    return dataset\n",
    "\n",
    "def make_dataset(partition='train'):\n",
    "    dataset = list(load_partition(partition).repeat(12).as_numpy_iterator())\n",
    "    x = dataset[:-1]\n",
    "    y = dataset[1:]\n",
    "    x_encoded = [one_hot_encoding(note) for note in x]\n",
    "    y_encoded = [one_hot_encoding(note) for note in y]\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x_encoded, y_encoded))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innovative-syracuse",
   "metadata": {},
   "source": [
    "The make_dataset() function is called to prepare the train, valid and test sets. At this point, each dataset is composed of a sequence of single notes represented via a one-hot encoding. Splitting each into a number of different sequences and then into batches is done in the call to the model.fit() method, so that we can experiment with the sequence length and number samples per batch.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sought-worry",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = make_dataset('train'), make_dataset('valid'), make_dataset('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heavy-constraint",
   "metadata": {},
   "source": [
    "### Defining and training the model\n",
    "\n",
    "The model is composed of a 3 stacked GRU units followed by a dense output layer with softmax activation. The inputs and outpus are of dimension 59 (corresponding to 57 possible notes plus the silence and end-of-file indications). The GRUs are twice as wide as the input and output dimension.\n",
    "\n",
    "A modified version of the keras GRU layer has been applied. The custom layer uses the GRU cell followed by layer normalization applied to the cell's output. This modification drastically improved both the model's performance and training speed.\n",
    "\n",
    "Because the model operates in a many-to-many scheme, every GRU layer returns its full sequence, which is used by the next layer.\n",
    "\n",
    "The model benefits significantly from regularization in the form of dropout. The same dropout rate of 20% has been applied to the recurrent units (for both the outputs and the state tensor) and the dense layer. Additional regularization through application of penalties to the L1 and L2 norms of the parameters has been tested but did not prove to be benefitial to performance, so the final model contains neither.\n",
    "\n",
    "We use keras' Sequential API to specify the model (as the model is linear, without any skip connections)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "norwegian-approval",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 2 -\n",
    "#.47->.34 @train/ .65->.59 @valid/ .67->.62 @test\n",
    "#01  with lr scheduling: .30 @train / .60 @valid / .65 @test\n",
    "#02 with dropout .2, .2, .2: .38/88% @train / .58/84% @valid / .58/83% @test\n",
    "#03 with dropout .3, .3, .2: .46 @train / .58 @valid / .59 @test\n",
    "#04 with dropout .2, .2, .2 and adjusted preprocessing (repeat 12) and lr schedule: .49/85% @train / .52/85% @valid / .53/84% @test\n",
    "#05 3 dense + dropout + bn, .2, .2, .2, 0: not good, didn't even finish (25/fev, 7:44)\n",
    "#06 3 dense + dropout + bn, .3, .3, .2, 0: even worse (25/fev, 13:06)\n",
    "#07 3 dense + dropout + bn, .2, .2, .2, 0, lr_0=0.05: diverged on epoch 2 (25/fev, 14:49)\n",
    "#08 3 dense + dropout, no bn, .2, .2, .2, 0, lr_0=0.01: .56 @train / .57 @valid / .59 @test (25/fev, 15:55)\n",
    "#09 - same as 04 + LR correction (begin at .01 instead of .007): subtle decrease in performance (proceed with LR reduced to .076) : .50/85% @train / .53/84% @valid / .54/84% @test (26/fev, 8:56)\n",
    "#10 - same as 04, lr logic corrected and lr_0 set to .0075: .48/86% @train / .50/85% @valid / .52/84% @test\n",
    "#11 - same as 10, with l2_penalty=1e-5: .49/85% @train / .52/85% @valid / .53/84% @test (27/fev, 9:42)\n",
    "#12 - same as 10, with l2_penalty=1e-4: .51/85% @train / .53/85% @valid / .55/84% @test (27/fev, 17:55)\n",
    "#13 - same as 10, with l2_penalty=1e-6: .48/85% @train / .51/85% @valid / .52/84% @test (28/fev, 8:31)\n",
    "    # 13 - not the best performance, but the best new song so far! (28/fev 18:50)\n",
    "    #forget about L2 reg\n",
    "#14 - same as 10, with reduce on plateau changed to .4 (instead of .3): .48/85% @train / .51/85% @valid / .52/84% @test (28/fev, 20:26)\n",
    "    #  4 pleateaus (2 pairs of 2) instead of 2, final LR smaller than benchmark, results marginally worse than benchmark\n",
    "    # proceed with .3 (maybe try smaller later)\n",
    "#15 - same as 10, with custom cell with layer normalization: .48/85% @train/ .50/85% @valid/ .52/84% @test (1/mar, 11:19)\n",
    "#16 - same as 15, experimenting with different values of gradient clipping:\n",
    "    # clip_norm=1 (BEST & fastest): .46/86% @train/ .48/85% @valid/ .50/85% @test (2/mar, 8:40) - first plateau at epoch 18, maintains LR higher than previous settings, beat all others at epoch 20\n",
    "    # clip_norm=2: .??/??% @train/ .??/??% @valid/ .??/??% @test (3/mar, 10:51) - plateaus @12/20/27 - mildly worse than previous, stopped manually at 86\n",
    "    # clip_norm=.5: .46/86% @train/ .48/85% @valid/ .50/85% @test (4/mar, 12:16) - plateaus @12/22/24 - marginally worse than clip_norm=1\n",
    "#17 - same as 16, reshaping network - add more units to the GRU\n",
    "    # input_dim * 3: .??/??% @train/ .??/??% @valid/ .??/??% @test (5/mar, ??:??): \n",
    "    \n",
    "#.??/??% @train/ .??/??% @valid/ .??/??% @test (??/???, ??:??)\n",
    "    \n",
    "input_dim = 46 + 2 + 11 # 46 notes + 2 controls (silence & eof) + 11 transposing half-steps\n",
    "\n",
    "rec_dropout, gru_dropout, dense_dropout = .2, .2, .2\n",
    "\n",
    "# define a GRU cell with layer normalization\n",
    "\n",
    "class LN_GRU_Cell(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=\"tanh\", dropout=0, recurrent_dropout=0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.dropout = dropout\n",
    "        self.recurrent_dropout = recurrent_dropout\n",
    "        self.state_size = units\n",
    "        self.output_size = units\n",
    "        self.GRU_cell = keras.layers.GRUCell(units, dropout=dropout, recurrent_dropout=recurrent_dropout, activation=None)\n",
    "        self.layer_norm = keras.layers.LayerNormalization()\n",
    "        self.activation = keras.activations.get(activation)\n",
    "    def call(self, inputs, states):\n",
    "        outputs, new_states = self.GRU_cell(inputs, states)\n",
    "        norm_outputs = self.activation(self.layer_norm(outputs))\n",
    "        return norm_outputs, [new_states]\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        custom_config = {'units':self.units,\n",
    "                         'dropout':self.dropout,\n",
    "                         'recurrent_dropout':self.recurrent_dropout,\n",
    "                         'activation':self.activation}\n",
    "        return {**base_config, **custom_config}\n",
    "    \n",
    "# DÁ PRA SALVAR ESSA CLASSE EM UM ARQUIVO PRA USAR DEPOIS NO CARREGAMENTO DO MODELO???\n",
    "\n",
    "model = keras.models.Sequential(name='model')\n",
    "\n",
    "model.add(keras.layers.RNN(LN_GRU_Cell(3*input_dim, dropout=gru_dropout, recurrent_dropout=rec_dropout), \n",
    "                           return_sequences=True, input_shape=[None, input_dim], name='LN_GRU1'))\n",
    "\n",
    "model.add(keras.layers.RNN(LN_GRU_Cell(3*input_dim, dropout=gru_dropout, recurrent_dropout=rec_dropout),\n",
    "                           return_sequences=True, name='LN_GRU2'))\n",
    "\n",
    "model.add(keras.layers.RNN(LN_GRU_Cell(3*input_dim, dropout=gru_dropout, recurrent_dropout=rec_dropout),\n",
    "                          return_sequences=True, name='LN_GRU3'))\n",
    "\n",
    "model.add(keras.layers.Dropout(dense_dropout, name='Dropout1'))\n",
    "model.add(keras.layers.Dense(input_dim, activation='softmax', name='Dense1'))\n",
    "\n",
    "# plan for model 2\n",
    "# dropout before dense layer (duh) - .47->.34 @train/ .65->.59 @valid/ .67->.62 @test\n",
    "# 4 bars of -1 - .48->.29 @train/ .65->.59 @valid/ .66->.59 @test / too many -1, songs too short, not very precise in outputing exactly 16\n",
    "# remove dropout from output layer: .50->.?? @train/ .66->.?? @valid/ .69->.?? @test\n",
    "# learning rate decay - did not improve results, but was able to approximate the results of 2 separate loops\n",
    "# shuffle after 1st batch (shuffle the sequences so that GD does not receive biased sequences) - only if not using stateful RNN\n",
    "# increase dropout on recurrent layers - slight decrease in performance\n",
    "# data augmentation - drastic improvement\n",
    "# 3 dense layers + with dropout + batch norm - decreased performance\n",
    "# layer normalization on GRUs\n",
    "# regularization parameters tuning\n",
    "# change optimizers - decrease inertia\n",
    "# decrease batch size\n",
    "# decrease the reduce on plateau reduction rate OR increase the reduce on plateau but decrease decay\n",
    "# stateful RNN \n",
    "    #(to learn longer paterns, maybe predict next entry without going through entire sequence) - \n",
    "    # not so simple, batching is complicated\n",
    "    # create a stateful NN and copy the weights from the trained model, use it to generate new music faster\n",
    "    # with a stateful RNN, try to implement MC dropout\n",
    "# gradient clipping to avoid large peaks in loss functions - monitor gradients to see what is happening in those peaks\n",
    "# consider adding dense layers (too few parameters in comparison to GRUs)\n",
    "# consider adding another GRU\n",
    "# increase patience when happy with the tuning\n",
    "\n",
    "\n",
    "#: .??/??% @train/ .??/??% @valid/ .??/??% @test (??/???, ??:??)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separated-electricity",
   "metadata": {},
   "source": [
    "The model is trained with the ADAM optimizer, which usually does not require much tuning other than that of the learning rate. Thus, the default values for these parameters were kept.\n",
    "\n",
    "The learning rate has been carefully adjusted for the training dynamics of this model. It was set at 0.075 at the first epoch, with two rules applied for its reduction during the training process:\n",
    "\n",
    "1. Power scheduling has been set to gradually decrease the learning rate as the training progresses. This type of scheduling is more severe in the beginning of the training, and becomes more mild at later epochs, which allows the training algorithm to learn the easier patterns in the beginning of training with a higher learning rate, and to be more parcimonious with the more sophisticated patterns learned near the end. The parameters of the scheduling have been set to that the learning rate reduces to around 1/2 of it's original value after 40 epochs, then to 1/3 after 40 more epochs and so on. \n",
    "\n",
    "2. A reduce-on-plateau callback has been set, which reduces the learning rate by a ratio of 0.3 every time training reaches the end of an epoch without an improvement of the loss metric as measured in the validation set. The patience term has been set at 1, meaning that the callback will reduce the learning rate after only 1 epoch without improvement. This may seem drastic, but the dataset has been drastically augmented (by a factor of 12), so each epoch contains a significant amount of gradient descent steps.\n",
    "\n",
    "Additionally, gradient clipping has been applied to curb the updates to the parameters in order to make training more stable and reduce sudden dips in performance due to an overshoot of promising parameter regions. The use of gradient clipping has reduced the incidence of the reduce-on-plateau callback, allowing the optimizer to keep a higher learning rate for longer without jeopardizing performance.\n",
    "\n",
    "As a final form of regularization, an early-stopping callback has been set in order to interrupt training after a number of epochs without improvement to the validation loss. The parameter setting _restore_best_weights = True_ ensures that the final model retains the best performance observed during training.\n",
    "\n",
    "The dataset is batched into sequences of 256 notes, or 64 notes per voice, which amounts to 8 bars of music per sequence (considering eighth notes). This allows the network to pick up on relatively long musical patterns. \n",
    "\n",
    "The appropriate loss is _categorical cross entropy_ - related to the model's ability to predict the next note correctly with a high degree of confidence. Accuracy is also measured.\n",
    "\n",
    "The model contains around 240,000 trainable parameters. The model is set to train for 100 epochs, but the early-stopping usually halts the training between 40 to 70 epochs. The full training process takes around 24 hours on a typical CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bearing-mechanics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "LN_GRU1 (RNN)                (None, None, 177)         126732    \n",
      "_________________________________________________________________\n",
      "LN_GRU2 (RNN)                (None, None, 177)         189390    \n",
      "_________________________________________________________________\n",
      "LN_GRU3 (RNN)                (None, None, 177)         189390    \n",
      "_________________________________________________________________\n",
      "Dropout1 (Dropout)           (None, None, 177)         0         \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, None, 59)          10502     \n",
      "=================================================================\n",
      "Total params: 516,014\n",
      "Trainable params: 516,014\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# First learning loop\n",
    "\n",
    "sequence_length = 256\n",
    "batch_size = 16\n",
    "\n",
    "# setup learning rate scheduler and gradient clipping value\n",
    "\n",
    "lr_0 = 0.0075\n",
    "lr_decay_rate = 12 # 12 to account for repetitions of the train set\n",
    "lr_decay_step = 40 # 1 update per epoch\n",
    "#lr_min = 0.0005\n",
    "\n",
    "clip_norm = 1\n",
    "\n",
    "def lr_scheduler_fn(epoch, lr):\n",
    "    new_lr = lr * (1 + lr_decay_rate*epoch/lr_decay_step) / (1 + lr_decay_rate*(epoch+1)/lr_decay_step) # current lr time ratio between current and previous lr\n",
    "    if epoch == 0:\n",
    "        new_lr = lr_0\n",
    "    print('Epoch {} / current learning rate: {} / new learning rate: {}'.format(epoch,np.round(lr,6),np.round(new_lr,6)))\n",
    "    #new_lr = np.max((new_lr, lr_min))\n",
    "    return new_lr\n",
    "\n",
    "lr_scheduler_callback = keras.callbacks.LearningRateScheduler(lr_scheduler_fn)\n",
    "\n",
    "# setup for early stopping and tensorboard callbacks\n",
    "\n",
    "if 'tb_logs' not in listdir(join(getcwd(), 'bach-chorales')):\n",
    "    mkdir(join(getcwd(), 'bach-chorales', 'tb_logs'))\n",
    "\n",
    "run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "log_dir = join(getcwd(), 'bach-chorales', 'tb_logs', run_id)\n",
    "\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir = log_dir, histogram_freq = 1)\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=4, restore_best_weights=True, verbose=True) # 2 epochs go over the train set 24 times\n",
    "lr_plateau_callback = keras.callbacks.ReduceLROnPlateau(factor=.3, min_lr = lr_0/100, patience=1, verbose=1) # 1 epoch go over the train set 12 times\n",
    "\n",
    "# compile model, batch the datasets and train model\n",
    "\n",
    "# PROBABLY SHOULDN'T BATCH THE VALIDATION SET! longer sequences tend to provide better prediction...\n",
    "# also shouldn't randomly transpose validation set\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate = lr_0, clipnorm = clip_norm)\n",
    "model.compile(optimizer=optimizer, loss = 'categorical_crossentropy', metrics = 'accuracy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-anthony",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 / current learning rate: 0.0075 / new learning rate: 0.0075\n",
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train.batch(sequence_length).batch(batch_size, drop_remainder=True).cache().prefetch(16),\n",
    "                    epochs = 100, # each epoch with augmented set ~ 12 epochs\n",
    "                    verbose = 2, # 1 : progress bar / 2 : one entry per epoch\n",
    "                    validation_data = valid.batch(sequence_length).batch(batch_size, drop_remainder=True).cache().prefetch(1),\n",
    "                    callbacks = [lr_scheduler_callback, lr_plateau_callback, tensorboard_callback, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-season",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Performance on train set:\")\n",
    "model.evaluate(train.batch(sequence_length).batch(batch_size, drop_remainder=True))\n",
    "print(\"Performance on valid set:\")\n",
    "model.evaluate(valid.batch(sequence_length).batch(batch_size, drop_remainder=True))\n",
    "print(\"Performance on test set:\")\n",
    "model.evaluate(test.batch(sequence_length).batch(batch_size, drop_remainder=True))\n",
    "\n",
    "plt.figure(figsize=(15,3))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('loss: categorical cross-entropy')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('metric: accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valuable-witch",
   "metadata": {},
   "source": [
    "Save the model in the _models_ directory, in a folder with the same _run_id_ used to save the TensorBoard logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chief-fiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not 'models' in listdir(join(getcwd(), 'bach-chorales')):\n",
    "    mkdir(join(getcwd(), 'bach-chorales', 'models'))\n",
    "\n",
    "filepath = join(getcwd(), 'bach-chorales', 'models', run_id + '.h5')\n",
    "model.save(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "royal-knowing",
   "metadata": {},
   "source": [
    "### Generating new music\n",
    "\n",
    "* Save the model in the end of previous section\n",
    "* Load the model here\n",
    "* check why aahs are not working on all channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "positive-picture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[65, 60, 57, 53],\n",
       "        [65, 60, 57, 53],\n",
       "        [65, 60, 57, 53],\n",
       "        [65, 60, 57, 53]],\n",
       "\n",
       "       [[65, 60, 57, 53],\n",
       "        [65, 60, 57, 53],\n",
       "        [65, 60, 57, 53],\n",
       "        [65, 60, 57, 53]],\n",
       "\n",
       "       [[67, 63, 58, 55],\n",
       "        [67, 63, 58, 55],\n",
       "        [67, 62, 58, 55],\n",
       "        [67, 62, 58, 55]],\n",
       "\n",
       "       [[67, 62, 58, 55],\n",
       "        [67, 62, 58, 55],\n",
       "        [67, 62, 58, 55],\n",
       "        [67, 62, 58, 55]],\n",
       "\n",
       "       [[67, 61, 58, 55],\n",
       "        [67, 61, 58, 55],\n",
       "        [67, 63, 58, 60],\n",
       "        [67, 63, 58, 60]],\n",
       "\n",
       "       [[68, 63, 60, 48],\n",
       "        [68, 63, 60, 48],\n",
       "        [68, 63, 60, 48],\n",
       "        [68, 63, 60, 48]],\n",
       "\n",
       "       [[68, 65, 53, 49],\n",
       "        [68, 65, 53, 49],\n",
       "        [68, 65, 61, 49],\n",
       "        [68, 65, 61, 49]],\n",
       "\n",
       "       [[70, 65, 61, 51],\n",
       "        [70, 65, 61, 51],\n",
       "        [70, 65, 60, 51],\n",
       "        [70, 65, 60, 51]],\n",
       "\n",
       "       [[68, 65, 56, 53],\n",
       "        [68, 65, 56, 53],\n",
       "        [68, 63, 60, 56],\n",
       "        [68, 63, 60, 56]],\n",
       "\n",
       "       [[68, 65, 61, 58],\n",
       "        [68, 65, 61, 56],\n",
       "        [68, 65, 61, 56],\n",
       "        [68, 65, 61, 56]],\n",
       "\n",
       "       [[70, 66, 61, 54],\n",
       "        [70, 66, 61, 54],\n",
       "        [70, 66, 61, 53],\n",
       "        [70, 66, 61, 53]],\n",
       "\n",
       "       [[77, 68, 63, 48],\n",
       "        [77, 68, 63, 48],\n",
       "        [77, 68, 62, 48],\n",
       "        [77, 68, 62, 48]],\n",
       "\n",
       "       [[75, 66, 57, 48],\n",
       "        [75, 66, 57, 48],\n",
       "        [75, 66, 57, 48],\n",
       "        [75, 66, 57, 48]],\n",
       "\n",
       "       [[70, 65, 58, 50],\n",
       "        [70, 65, 58, 50],\n",
       "        [70, 65, 58, 50],\n",
       "        [70, 65, 58, 50]],\n",
       "\n",
       "       [[72, 63, 58, 48],\n",
       "        [72, 63, 58, 48],\n",
       "        [72, 63, 58, 48],\n",
       "        [72, 63, 58, 48]],\n",
       "\n",
       "       [[72, 61, 56, 53],\n",
       "        [72, 61, 56, 53],\n",
       "        [73, 61, 56, 53],\n",
       "        [73, 61, 56, 53]],\n",
       "\n",
       "       [[75, 63, 56, 51],\n",
       "        [75, 63, 56, 51],\n",
       "        [72, 63, 56, 56],\n",
       "        [72, 63, 56, 56]],\n",
       "\n",
       "       [[72, 63, 56, 56],\n",
       "        [72, 63, 56, 56],\n",
       "        [72, 63, 56, 56],\n",
       "        [72, 63, 56, 56]],\n",
       "\n",
       "       [[68, 63, 56, 48],\n",
       "        [68, 63, 56, 48],\n",
       "        [68, 63, 56, 48],\n",
       "        [68, 63, 56, 48]],\n",
       "\n",
       "       [[65, 61, 58, 46],\n",
       "        [65, 61, 58, 46],\n",
       "        [65, 62, 56, 46],\n",
       "        [65, 62, 56, 46]],\n",
       "\n",
       "       [[63, 58, 55, 39],\n",
       "        [63, 58, 55, 39],\n",
       "        [63, 58, 55, 39],\n",
       "        [63, 58, 55, 39]],\n",
       "\n",
       "       [[63, 58, 55, 39],\n",
       "        [63, 58, 55, 39],\n",
       "        [63, 58, 55, 39],\n",
       "        [63, 58, 55, 39]],\n",
       "\n",
       "       [[-1, -1, -1, -1],\n",
       "        [62, 57, 54, 38],\n",
       "        [62, 57, 54, 38],\n",
       "        [62, 57, 54, 38]],\n",
       "\n",
       "       [[62, 57, 54, 38],\n",
       "        [67, 59, 55, 52],\n",
       "        [67, 59, 55, 52],\n",
       "        [67, 59, 55, 52]],\n",
       "\n",
       "       [[67, 59, 55, 52],\n",
       "        [69, 61, 52, 45],\n",
       "        [69, 61, 52, 45],\n",
       "        [69, 61, 52, 45]],\n",
       "\n",
       "       [[69, 61, 52, 45],\n",
       "        [67, 62, 50, 47],\n",
       "        [67, 62, 50, 47],\n",
       "        [67, 61, 52, 45]],\n",
       "\n",
       "       [[67, 61, 52, 45],\n",
       "        [62, 57, 54, 38],\n",
       "        [62, 57, 54, 38],\n",
       "        [62, 57, 54, 38]],\n",
       "\n",
       "       [[62, 57, 54, 38],\n",
       "        [62, 57, 54, 38],\n",
       "        [62, 57, 54, 38],\n",
       "        [62, 57, 54, 38]],\n",
       "\n",
       "       [[62, 57, 54, 38],\n",
       "        [66, 62, 59, 47],\n",
       "        [66, 62, 59, 47],\n",
       "        [66, 62, 59, 47]],\n",
       "\n",
       "       [[66, 62, 59, 47],\n",
       "        [69, 64, 61, 45],\n",
       "        [69, 64, 61, 45],\n",
       "        [69, 64, 61, 45]],\n",
       "\n",
       "       [[69, 64, 61, 45],\n",
       "        [69, 64, 61, 45],\n",
       "        [69, 64, 61, 45],\n",
       "        [69, 64, 61, 45]],\n",
       "\n",
       "       [[69, 64, 61, 45],\n",
       "        [71, 69, 66, 51],\n",
       "        [71, 69, 66, 51],\n",
       "        [71, 69, 66, 51]],\n",
       "\n",
       "       [[71, 69, 66, 51],\n",
       "        [71, 67, 64, 52],\n",
       "        [71, 67, 64, 52],\n",
       "        [71, 67, 64, 52]],\n",
       "\n",
       "       [[71, 67, 64, 52],\n",
       "        [71, 67, 63, 47],\n",
       "        [71, 67, 63, 47],\n",
       "        [71, 67, 63, 47]],\n",
       "\n",
       "       [[71, 67, 63, 47],\n",
       "        [71, 67, 63, 47],\n",
       "        [71, 67, 63, 47],\n",
       "        [71, 67, 63, 47]],\n",
       "\n",
       "       [[71, 67, 63, 47],\n",
       "        [76, 71, 64, 50],\n",
       "        [76, 71, 64, 50],\n",
       "        [76, 71, 66, 50]],\n",
       "\n",
       "       [[76, 71, 66, 50],\n",
       "        [71, 69, 64, 52],\n",
       "        [71, 69, 64, 52],\n",
       "        [71, 68, 64, 52]],\n",
       "\n",
       "       [[71, 68, 64, 52],\n",
       "        [69, 64, 60, 45],\n",
       "        [69, 64, 60, 45],\n",
       "        [69, 64, 60, 48]],\n",
       "\n",
       "       [[69, 64, 60, 48],\n",
       "        [71, 63, 59, 47],\n",
       "        [71, 63, 59, 47],\n",
       "        [71, 63, 57, 47]],\n",
       "\n",
       "       [[71, 63, 57, 47],\n",
       "        [71, 64, 56, 52],\n",
       "        [71, 64, 56, 52],\n",
       "        [71, 64, 56, 52]],\n",
       "\n",
       "       [[71, 64, 56, 52],\n",
       "        [71, 64, 55, 52],\n",
       "        [71, 64, 55, 52],\n",
       "        [71, 64, 55, 51]],\n",
       "\n",
       "       [[71, 64, 55, 51],\n",
       "        [71, 63, 56, 53],\n",
       "        [71, 63, 56, 53],\n",
       "        [71, 65, 56, 53]],\n",
       "\n",
       "       [[71, 65, 56, 53],\n",
       "        [69, 64, 61, 57],\n",
       "        [69, 64, 61, 57],\n",
       "        [69, 64, 61, 57]],\n",
       "\n",
       "       [[69, 64, 61, 57],\n",
       "        [73, 68, 64, 49],\n",
       "        [73, 68, 64, 49],\n",
       "        [73, 68, 64, 49]],\n",
       "\n",
       "       [[73, 68, 64, 49],\n",
       "        [73, 68, 64, 49],\n",
       "        [73, 68, 64, 49],\n",
       "        [73, 68, 64, 49]],\n",
       "\n",
       "       [[73, 68, 64, 49],\n",
       "        [73, 68, 64, 49],\n",
       "        [73, 68, 64, 49],\n",
       "        [73, 68, 64, 49]],\n",
       "\n",
       "       [[73, 68, 64, 49],\n",
       "        [-1, -1, -1, -1],\n",
       "        [76, 67, 60, 60],\n",
       "        [76, 67, 60, 60]],\n",
       "\n",
       "       [[76, 66, 60, 60],\n",
       "        [76, 66, 60, 60],\n",
       "        [77, 69, 60, 53],\n",
       "        [77, 69, 60, 53]],\n",
       "\n",
       "       [[77, 69, 60, 53],\n",
       "        [77, 69, 60, 53],\n",
       "        [74, 69, 60, 54],\n",
       "        [74, 69, 60, 54]],\n",
       "\n",
       "       [[74, 67, 60, 59],\n",
       "        [74, 67, 60, 59],\n",
       "        [74, 67, 60, 56],\n",
       "        [74, 67, 60, 56]]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# music generation\n",
    "\n",
    "Length = 800 # number of new notes on all voices, actual piece length is Length/4\n",
    "Temperature = 1.0 # not really temperature (which should be applied before softmax), but works similarly (smaller values are more adventurous, larger values are more conservative)\n",
    "\n",
    "song = []\n",
    "song_encoded = one_hot_encoding(-1).reshape((1,1,input_dim)).repeat(16, axis=1)\n",
    "song_encoded.shape\n",
    "\n",
    "new_note = -1\n",
    "new_note_encoding = one_hot_encoding(new_note).reshape((1,1,input_dim))\n",
    "\n",
    "# music generation loop\n",
    "\n",
    "for _ in range(Length):\n",
    "    p = model.predict(song_encoded)[:,-1,:].flatten() # the model is reading the entire chorale up to this point, which makes it very slow for long sequences. This should be improved, providing a limited number os samples for each new note or making the network remember the last state.\n",
    "    p = p**Temperature / (p**Temperature).sum()\n",
    "    \n",
    "    out = np.random.choice(input_dim, p=p)\n",
    "    new_note_encoding = np.zeros((1,1,input_dim))\n",
    "    new_note_encoding[0,0,out] = 1\n",
    "    new_note = one_hot_decoding(new_note_encoding)\n",
    "\n",
    "    song.append(new_note)\n",
    "    extended_song = np.zeros((song_encoded.shape[0], song_encoded.shape[1]+1, song_encoded.shape[2]))\n",
    "    extended_song[:,:-1,:] = song_encoded\n",
    "    extended_song[:,-1,:] = new_note_encoding\n",
    "    song_encoded = extended_song\n",
    "\n",
    "# print chorale as np array    \n",
    "np.array(song).reshape((-1,4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "covered-dallas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>note1</th>\n",
       "      <th>note2</th>\n",
       "      <th>note3</th>\n",
       "      <th>note4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>60</td>\n",
       "      <td>57</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65</td>\n",
       "      <td>60</td>\n",
       "      <td>57</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65</td>\n",
       "      <td>60</td>\n",
       "      <td>57</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65</td>\n",
       "      <td>60</td>\n",
       "      <td>57</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65</td>\n",
       "      <td>60</td>\n",
       "      <td>57</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>63</td>\n",
       "      <td>58</td>\n",
       "      <td>55</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>63</td>\n",
       "      <td>58</td>\n",
       "      <td>55</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>63</td>\n",
       "      <td>58</td>\n",
       "      <td>55</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>63</td>\n",
       "      <td>58</td>\n",
       "      <td>55</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>63</td>\n",
       "      <td>58</td>\n",
       "      <td>55</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    note1  note2  note3  note4\n",
       "0      65     60     57     53\n",
       "1      65     60     57     53\n",
       "2      65     60     57     53\n",
       "3      65     60     57     53\n",
       "4      65     60     57     53\n",
       "..    ...    ...    ...    ...\n",
       "83     63     58     55     39\n",
       "84     63     58     55     39\n",
       "85     63     58     55     39\n",
       "86     63     58     55     39\n",
       "87     63     58     55     39\n",
       "\n",
       "[88 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clip entries before beginning\n",
    "\n",
    "first_note_position = 0\n",
    "for position, note in enumerate(song):\n",
    "    if note != -1:\n",
    "        first_note_position = position\n",
    "        break\n",
    "\n",
    "new_chorale = np.array(song[first_note_position : -4 + (first_note_position % 4)]).reshape(-1,4)\n",
    "        \n",
    "# clip entries after eof\n",
    "\n",
    "first_eof = (new_chorale.min(axis = 1) == -1).astype('int').argmax()\n",
    "if first_eof > 0:\n",
    "    new_chorale = new_chorale[:first_eof, :]\n",
    "        \n",
    "# convert finished product to data frame\n",
    "\n",
    "new_chorale = pd.DataFrame(new_chorale, columns=['note1','note2','note3','note4'])\n",
    "new_chorale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "wrong-eclipse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# midi encoding with legato (attack only when new note is different from current one)\n",
    "\n",
    "new_chorale_midi = mido.MidiFile(type=1)\n",
    "\n",
    "time_unit = 360\n",
    "instrument = 52 # choir aahs\n",
    "volume = [50, 50, 60, 75] # volume for each channel\n",
    "\n",
    "for channel in range(4):\n",
    "    track = mido.MidiTrack()\n",
    "    track.append(mido.Message('program_change', channel = channel, program = instrument, time = 0))\n",
    "    previous_note = 0\n",
    "    steps = 1\n",
    "    \n",
    "    for pos, note in enumerate(new_chorale.iloc[:, channel]):\n",
    "        if note == previous_note:\n",
    "            steps += 1\n",
    "        if note != previous_note:\n",
    "            if pos != 0:\n",
    "                track.append(mido.Message('note_off', channel=channel, note=previous_note, time = steps * time_unit))\n",
    "            track.append(mido.Message('note_on', channel=channel, note=note, velocity=volume[channel], time=0))\n",
    "            previous_note = note\n",
    "            steps = 1\n",
    "            \n",
    "    new_chorale_midi.tracks.append(track)\n",
    "    \n",
    "filename = 'new_chorale_' + time.strftime(\"_%Y_%m_%d-%H_%M_%S\") + '.mid'\n",
    "filepath = join(getcwd(), 'bach-chorales', 'new')\n",
    "\n",
    "new_chorale_midi.save(join(filepath, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "treated-toner",
   "metadata": {},
   "source": [
    "### Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dependent-rings",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this class works for training and inference, but does not play nice with model saving.\n",
    "# code here as backup for the modified version above\n",
    "\n",
    "#class LN_GRU_Cell(keras.layers.Layer):\n",
    "#    def __init__(self, units, activation=\"tanh\", dropout=0, recurrent_dropout=0, **kwargs):\n",
    "#        super().__init__(**kwargs)\n",
    "#        self.state_size = units\n",
    "#        self.output_size = units\n",
    "#        self.GRU_cell = keras.layers.GRUCell(units, dropout=dropout, recurrent_dropout=recurrent_dropout, activation=None)\n",
    "#        self.layer_norm = keras.layers.LayerNormalization()\n",
    "#        self.activation = keras.activations.get(activation)\n",
    "#    def call(self, inputs, states):\n",
    "#        outputs, new_states = self.GRU_cell(inputs, states)\n",
    "#        norm_outputs = self.activation(self.layer_norm(outputs))\n",
    "#        return norm_outputs, [new_states]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "lesbian-genetics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check what are the lowest and hightest notes in the corpus\n",
    "\n",
    "#files = []\n",
    "#partition = ['train', 'valid', 'test']\n",
    "\n",
    "#for p in partition:\n",
    "#    filename = listdir(join(getcwd(), 'bach-chorales', p))\n",
    "#    for file in filename:\n",
    "#        files.append(join(getcwd(), 'bach-chorales', p, file))\n",
    "\n",
    "#pitch_range = []        \n",
    "\n",
    "#for file in files:\n",
    "#    df = pd.read_csv(file)\n",
    "#    df = df.where(df != 0, other = None)\n",
    "#    pitch_range.append((df.min().min(), df.max().max()))\n",
    "\n",
    "#np.array(pitch_range).min(), np.array(pitch_range).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adopted-rolling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 1 - .46->.34 @train / .66->.60 @valid / .67->.62 @test\n",
    "#model = keras.models.Sequential()\n",
    "#model.add(keras.layers.GRU(input_dim*2, dropout = .1, recurrent_dropout = .1, input_shape = [None, input_dim], return_sequences = True))\n",
    "#model.add(keras.layers.GRU(input_dim*2, dropout = .1, recurrent_dropout = .1, return_sequences = True))\n",
    "#model.add(keras.layers.GRU(input_dim*2, dropout = .1, recurrent_dropout = .1, return_sequences = True))\n",
    "#model.add(keras.layers.Dense(input_dim, kernel_regularizer = keras.regularizers.l2(l2=0)))\n",
    "#model.add(keras.layers.Dropout(.1))\n",
    "#model.add(keras.layers.Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-consistency",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "focused-recipient",
   "metadata": {},
   "source": [
    "##### Second learning loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fresh-diagnosis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second learning loop\n",
    "\n",
    "#learning_rate = 0.001 # 0.01 -> 0.001 -> 0.0001\n",
    "#sequence_length = 256 # 256\n",
    "#batch_size = 16 # 16 -> 16 -> 64\n",
    "\n",
    "#optimizer = keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "\n",
    "#tensorboard_callback = keras.callbacks.TensorBoard(log_dir = log_dir+'_loop_02', histogram_freq = 1)\n",
    "\n",
    "#model.compile(optimizer=optimizer, loss = 'categorical_crossentropy')\n",
    "\n",
    "# PROBABLY SHOULDN'T BATCH THE VALIDATION SET! longer sequences tend to provide better prediction...\n",
    "\n",
    "#history = model.fit(train.batch(sequence_length).batch(batch_size, drop_remainder=True).cache().prefetch(16),\n",
    "#                    epochs = 1000,\n",
    "#                    validation_data = valid.batch(sequence_length).batch(batch_size, drop_remainder=True).cache().prefetch(1),\n",
    "#                    callbacks = [early_stopping, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "effective-apache",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.evaluate(train.batch(sequence_length).batch(batch_size, drop_remainder=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "blocked-vertical",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.evaluate(valid.batch(sequence_length).batch(batch_size, drop_remainder=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "unlimited-administration",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.evaluate(test.batch(sequence_length).batch(batch_size, drop_remainder=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "modern-feature",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(history.history['loss'])\n",
    "#plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-burke",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "atmospheric-fabric",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model without layer normalization\n",
    "\n",
    "#model = keras.models.Sequential(name='model')\n",
    "#model.add(keras.layers.GRU(2 * input_dim, dropout = gru_dropout, recurrent_dropout = rec_dropout, \n",
    "#                           input_shape = [None, input_dim], return_sequences = True, name='GRU1'))\n",
    "#model.add(keras.layers.GRU(2 * input_dim, dropout = gru_dropout, recurrent_dropout = rec_dropout, \n",
    "#                           return_sequences = True, name='GRU2'))\n",
    "#model.add(keras.layers.GRU(2 * input_dim, dropout = gru_dropout, recurrent_dropout = rec_dropout, \n",
    "#                           return_sequences = True, name='GRU3'))\n",
    "#model.add(keras.layers.Dropout(dense_dropout, name='Dropout1'))\n",
    "#model.add(keras.layers.Dense(input_dim, activation='softmax', name='Dense1'))\n",
    "\n",
    "#######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "returning-repository",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
